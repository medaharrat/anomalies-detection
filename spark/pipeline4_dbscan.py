# -*- coding: utf-8 -*-
"""pipeline4_dbscan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X8M8SNj6bdSU4qGCAEmw94XMULE9_86f
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.core.pylabtools import figsize
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import IsolationForest
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import GridSearchCV

# %matplotlib inline

final=pd.read_csv("SWAT.csv")

"""# **DBSCAN Part**"""

final=final.drop(['Time','Anomalies'],axis=1)

final.head()

# DBSCAN
from sklearn.cluster import DBSCAN

dbb=DBSCAN(eps=2.5,min_samples=5)
dbb.fit(final)

outlier_pos = np.where(dbb.labels_ == -1)[0]

x = []; y = [];
for pos in outlier_pos:
    x.append(np.array(final['PC6'])[pos])
    y.append(final['PC6'].index[pos])

plt.plot(final['PC6'].loc[final['PC6'].index], 'k-')
plt.plot(y,x,'r*', markersize=8)

labels = dbb.labels_
core_samples = np.zeros_like(labels, dtype = bool)
core_samples[dbb.core_sample_indices_] = True

#converting the array into dataframe to group by labels and check the counts
labels_df =  pd.DataFrame(labels, columns=['cluster'])
labels_df['cluster'].value_counts()

labels_df.head()

result = pd.concat([final, labels_df], axis=1)

result.head()

result["cluster"].replace({-1: 1, 0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0,7: 0}, inplace=True)

result.head()

result['cluster'].value_counts()

len(result.columns)

"""# **Decision Tree part**"""

# Load libraries
import pandas as pd
from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier
from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation

X = result.iloc[:,  0:47]
y = result.cluster

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test

# Create Decision Tree classifer object
clf = DecisionTreeClassifier()

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

with open('./models/pipeline3.pickle', 'wb') as f:
    pickle.dump(model3, f)